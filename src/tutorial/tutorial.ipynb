{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureFlex 0.1.0\n",
    "### Autorzy: Andrii Voznesenskyi, Bartosz Kaczorowski\n",
    "\n",
    "**FeatureFlex** to pakiet AutoML skierowany do badaczy i specjalistów zajmujących się systemami rekomendacji opartymi na głębokim uczeniu. Odpowiada on na problem efektywnego zarządzania cechami wejściowymi w dużych zestawach danych. Dzięki temu może stanowić świetne narzędzie dla firm e-commerce lub platform streamingowych, które wykorzystają systemy rekomendacji na co dzień.\n",
    "\n",
    "**FeatureFlex** specjalizuje się w:\n",
    "- automatycznym wyborze najistotniejszych cech dla danego zbioru,\n",
    "- zwiększaniu efektywności systemów rekomendacji,\n",
    "- poprawie dokładności przewidywania preferencji podczas analizy predykcyjnej.\n",
    "\n",
    "Pakiet inspirowany był pracą [*AutoField: Automating Feature Selection in Deep Recommender Systems*](https://arxiv.org/pdf/2204.09078). Autorzy artykułu oprócz podania własnego rozwiązania rozważają tam między innymi metody takie jak:\n",
    "- manualna selekcja - ta wymaga jednak nakładów ludzkich i wiedzy eksperckiej,\n",
    "- Grid/Random Search - porównywalne jeśli chodzi o dokładność, jednak słabo skalujące się i będące wymagające obliczeniowo,\n",
    "- Lasso/Decision Trees - choć czasami stosowane, nie sprawdzają się jednak dobrze dla głębokich systemów rekomendacji.\n",
    "\n",
    "Stąd idea stworzenia systemu AutoML, który odpowie na powyższe problemy.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zawartość pakietu\n",
    "\n",
    "Przepływ pracy z danymi można podzielić na trzy cześci, za które odpowiedzialne są następujące klasy:\n",
    "1. Przetwarzanie danych (preprocessing):\n",
    "- `DataPreprocessor` - przetwarza dane z zadanego zbioru przy pomocy metody `preprocess`, opcjonalnie pozwala na manualny wybór cech.\n",
    "\n",
    "2. Selekcja i optymalizacja modeli:\n",
    "- `EnhancedFeatureSelector` - wybiera cechy przy użyciu trenowalnego modelu, udostępnia dwie metody wyboru najistotniejszych cech:\n",
    "     - `select_via_shap` - wykorzystuje pakiet ([SHapley Additive exPlanations](https://shap.readthedocs.io/en/latest/)) do wyboru cech, których ważność ustalana jest przy użyciu lasu losowego,\n",
    "     - `select_via_model_optimizer` - stosuje własny model AutoML do wyboru cech (patrz poniżej).\n",
    "\n",
    "- `ModelOptimizer` - automatycznie wybiera i optymalizuje modele uczenia maszynowego przy pomocy metody `optimize_model`, stosuje do tego *Grid Search* wykorzystując pole pod krzywą ROC i własny mechanizm kroswalidacji. Modele poddawane przeszukiwaniu w obecnej wersji: *RandomForest*, *GradientBoosting*, *LogisticRegression*, *SVM*, *XGBoost*, *KNN*.\n",
    "\n",
    "3. Ewaluacja i podsumowanie wyników:\n",
    "- `ModelEvaluator` - oblicza metryki, rysuje wykresy i generuje raporty w formie konsolowej lub pliku HTML dla wybranego modelu. Wybrane metryki: *AUC*, *Accuracy*, *Precission*, *Recall*, *F1-Score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "src_path = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przykładowy przepływ pracy\n",
    "\n",
    "### Wybór zbioru i przetwarzanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytano zbiór: world-happiness-report-2021.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import DataPreprocessor\n",
    "\n",
    "# Wybór zbioru danych\n",
    "dataset = \"../../data/world-happiness-report-2021.csv\"\n",
    "data = pd.read_csv(dataset)\n",
    "print(\"Wczytano zbiór: world-happiness-report-2021.csv\")\n",
    "\n",
    "# Określenie zbioru cech\n",
    "columns = [\n",
    "    \"Country name\", \"Regional indicator\", \"Ladder score\", \"Logged GDP per capita\", \n",
    "    \"Social support\", \"Healthy life expectancy\", \"Freedom to make life choices\", \n",
    "    \"Generosity\", \"Perceptions of corruption\"\n",
    "]\n",
    "data = data[columns]\n",
    "\n",
    "target_column = \"Ladder score\"\n",
    "data[target_column] = (data[target_column] > data[target_column].mean()).astype(int)\n",
    "\n",
    "# Przetwarzanie danych\n",
    "preprocessor = DataPreprocessor()\n",
    "X, y, _ = preprocessor.preprocess(\n",
    "    data,               # zbiór danych w postaci ramki\n",
    "    target_column       # nazwa kolumny zawierającej etykiety\n",
    ")\n",
    "\n",
    "# Podział przetworzonego zbioru na treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wybór najistotniejszych cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bakaczor/Desktop/Projects/AutoML/2/CS-MINI-2024Z-AutoML_project_2/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Model Optimization: 100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "from feature_selector import EnhancedFeatureSelector\n",
    "\n",
    "selector = EnhancedFeatureSelector(\n",
    "    input_dim=X_train.shape[1]  # liczba kolumn\n",
    ")\n",
    "\n",
    "# Wybór liczby i metody ekstrakcji cech\n",
    "n_features = 10\n",
    "# top_features = selector.select_via_shap(X_train, y_train, n_features=n_features)\n",
    "top_features = selector.select_via_model_optimizer(X_train, y_train, n_features=n_features)\n",
    "\n",
    "reduced_selector = EnhancedFeatureSelector(input_dim=len(top_features))\n",
    "\n",
    "# Ograniczenie zbioru danych do wyekstrahowanych cech\n",
    "if hasattr(X_train, \"toarray\"):\n",
    "    X_train_dense = X_train.toarray()[:, top_features]\n",
    "    X_test_dense = X_test.toarray()[:, top_features]\n",
    "else:\n",
    "    X_train_dense = X_train[:, top_features]\n",
    "    X_test_dense = X_test[:, top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wybór i optymalizacja modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Optimization: 100%|██████████| 6/6 [00:05<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Score (CV AUC): 0.9779316712834719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from model_optimizer import ModelOptimizer\n",
    "    \n",
    "# Opcjonalnie: redukcja nierówności powstałych w zbiorze,\n",
    "# stosując technikę oversamplingu SMOTE-Tomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_res, y_train_res = smote_tomek.fit_resample(X_train_dense, y_train)\n",
    "\n",
    "# Wybór i optymalizacja modelu\n",
    "optimizer = ModelOptimizer()\n",
    "best_model, best_score = optimizer.optimize_model(\n",
    "    X_train_res,    # macierz cech\n",
    "    y_train_res     # wektor etykiet\n",
    ")\n",
    "print(f\"Best Model Score (CV AUC): {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ewaluacja uzyskanego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model predictions...\n",
      "\n",
      "=== Evaluation Metrics ===\n",
      "AUC: 0.9420\n",
      "Accuracy: 0.9000\n",
      "Precision: 0.9333\n",
      "Recall: 0.8750\n",
      "F1-Score: 0.9032\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[13  1]\n",
      " [ 2 14]]\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8667    0.9286    0.8966        14\n",
      "           1     0.9333    0.8750    0.9032        16\n",
      "\n",
      "    accuracy                         0.9000        30\n",
      "   macro avg     0.9000    0.9018    0.8999        30\n",
      "weighted avg     0.9022    0.9000    0.9001        30\n",
      "\n",
      "Evaluation Results: {'AUC': 0.9419642857142857, 'Accuracy': 0.9, 'Precision': 0.9333333333333333, 'Recall': 0.875, 'F1-Score': 0.9032258064516129}\n"
     ]
    }
   ],
   "source": [
    "from evaluation import ModelEvaluator\n",
    "\n",
    "evaluator = ModelEvaluator()\n",
    "evaluation_results = evaluator.evaluate(\n",
    "    best_model,                     # wybrany model\n",
    "    X_test_dense,                   # macierz cech\n",
    "    y_test,                         # wektor etykiet\n",
    "    output_format=\"console\",        # metoda prezentacji - \"console\" lub \"html\"\n",
    ")\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatyzacja\n",
    "W pliku `main.py` dostępna jest funkcja pozwalająca na automatyzację całego przedstawionego procesu. Użyjemy jej do wygenerowania raportu w postaci HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Splitting data into train and test sets...\n",
      "Performing feature selection...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Optimization: 100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying SMOTE-Tomek on the training set...\n",
      "Optimizing models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model Optimization: 100%|██████████| 6/6 [00:04<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Score (CV AUC): 0.9779316712834719\n",
      "Evaluating model...\n",
      "Evaluating model predictions...\n",
      "HTML report saved to: ./evaluation_report_happiness.html\n",
      "Evaluation Results: {'AUC': 0.9419642857142857, 'Accuracy': 0.9, 'Precision': 0.9333333333333333, 'Recall': 0.875, 'F1-Score': 0.9032258064516129}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <html>\n",
       "          <head>\n",
       "            <title>Evaluation Report</title>\n",
       "            <meta charset=\"UTF-8\">\n",
       "            <style>\n",
       "                body { font-family: Arial, sans-serif; margin: 20px; }\n",
       "                h1, h2 { color: #2c3e50; }\n",
       "                ul { list-style-type: none; padding: 0; }\n",
       "                li { margin: 5px 0; font-size: 16px; }\n",
       "                pre { background-color: #f4f4f4; padding: 10px; border-radius: 5px; }\n",
       "                img { margin: 10px 0; border: 1px solid #ddd; border-radius: 5px; }\n",
       "                .key-metrics { padding: 10px; background: #ecf0f1; border: 1px solid #bdc3c7; border-radius: 5px; }\n",
       "            </style>\n",
       "          </head>\n",
       "          <body>\n",
       "            <h1>Evaluation Report</h1>\n",
       "            <div class=\"key-metrics\">\n",
       "              <h2>Key Metrics</h2>\n",
       "              <ul><li><strong>AUC:</strong> 0.9420</li><li><strong>Accuracy:</strong> 0.9000</li><li><strong>Precision:</strong> 0.9333</li><li><strong>Recall:</strong> 0.8750</li><li><strong>F1-Score:</strong> 0.9032</li></ul>\n",
       "            </div>\n",
       "            <h2>Confusion Matrix</h2><img src=\"confusion_matrix.png\" width=\"300\">\n",
       "            <h2>ROC Curve</h2><img src=\"roc_curve.png\" width=\"300\">\n",
       "            <h2>Precision-Recall Curve</h2><img src=\"precision_recall_curve.png\" width=\"300\">\n",
       "            <h2>Classification Report</h2>\n",
       "            <pre>              precision    recall  f1-score   support\n",
       "\n",
       "           0     0.8667    0.9286    0.8966        14\n",
       "           1     0.9333    0.8750    0.9032        16\n",
       "\n",
       "    accuracy                         0.9000        30\n",
       "   macro avg     0.9000    0.9018    0.8999        30\n",
       "weighted avg     0.9022    0.9000    0.9001        30\n",
       "</pre>\n",
       "          </body>\n",
       "        </html>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main import preprocess_and_train\n",
    "from IPython.display import HTML\n",
    "\n",
    "preprocess_and_train(data, target_column=target_column, output_filename=\"evaluation_report_happiness.html\", output_path=\".\")\n",
    "HTML(filename=\"./evaluation_report_happiness.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
